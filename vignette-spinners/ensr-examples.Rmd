---
title: "Elastic Net SearcheR Examples"
subtitle: "ensr package version `r packageVersion('ensr')`"
author: "Peter E. DeWitt"
date: "`r Sys.Date()`"
output:
 rmarkdown::html_vignette:
   toc: true
   number_sections: true
bibliography: references.bib
vignette: >
 %\VignetteEngine{knitr::rmarkdown}
 %\VignetteIndexEntry{ensr-examples}
 %\VignetteEncoding{UTF-8}
---

```{r label=setup, include = FALSE}
library(knitr)
knitr::opts_chunk$set(collapse = TRUE, fig.width = 6, fig.height = 4)
options(qwraps2_markup = "markdown")
```


The primary purpose of the ensr package is to provide methods for searching
for preferable values of $\lambda$ and $\alpha$ in elastice net regression.
This This vignette starts with a
summary of elastic net regression and the use/limitations of the
[glmnet](https://cran.r-studio.com/package=glmnet) pacakge.  Examples of data
set preperation follow and the vignette concludes with elastic net regression
results.


```{r label="load_and_attach_ensr"}
library(ensr)
library(data.table)
library(ggplot2)
library(ggforce)
options(datatable.print.topn  = 3L,
        datatable.print.nrows = 3L)
```


# Elastic Net Regression

Elastic Net Regression [@friedman2010regularization] is a penalized linear
modeling approach that is a mixture of ridge regression [@hoerl1970ridge],
and lasso regression [@tibshirani1996regression].  Ridge regression
reducing the impact of co-linearity, and lasso
reduces the dimensionality of the support by shrinking some of the regression
coefficients to zero.  Elastic net does both of these by solving the
following equation for gaussian responses:
$$\min_{\beta_0, \beta \in \mathbb{R}^{p+1}} \frac{1}{2N} \sum_{i = 1}^{N}
\left( y_i - \beta_0 - x_i^T \beta \right)^2 + \lambda \left[ \left(1 -
\alpha \right) \frac{\left \lVert \beta \right \rVert_{2}^{2}}{2} + \alpha
\left \lVert \beta \right \rVert_{1} \right],$$
where $\lambda \geq 0$ is the complexity parameter and $0 \leq \alpha \leq 1$
is the compromise between ridge $\left(\alpha = 0\right)$ and lasso $\left(
\alpha = 1 \right).$

One advantage for $0 < \alpha < 1,$ compared to lasso is that elastic net
will consistently return the same set of non-zero coefficients when some of
the predictors are highly correlated.  Lasso, $\alpha = 1,$ has the draw back
of returning differing sets of non-zero coefficients when highly correlated
predictors are in the model.

A benefit of elastic net regression is that the $\beta$ vector can easily be
programmed into any other software package capable of matrix, or even simple,
arithmetic.  So, while a GBM model might be a better fit of the data than the
linear model found via elastic net, GBM models are extremely difficult, or
impossible to export to other tools.

The `cv.glmnet` call from the glmnet package is used for fitting elastic
nets.  The value of $\alpha$ must be defined.  To search for a preferable
set of $\lambda$ and $\alpha$ values require fitting several models with
different $\alpha$ values and then searching for a preferable model.
Read the "Details" section in `help("cv.glmnet")`.

# Data Sets

There are two data sets provided in the ensr package for examples.

1. `tbi` is a synthetic data set for classifying three different types of
traumatic brain injury by a set of predictors.

2. `landfill` is a synthetic data set similar similar to ones generated by
computer models of water percolating through landfill.

Detail on the construction and specifics of each of these data sets is
provided in the "ensr-datasets" vignette:

```{r, eval = FALSE}
vignette("ensr-datasets", package = "ensr")
```

```{r }
data(tbi, package = "ensr")
data(landfill, package = "ensr")
```


# Searching for $\lambda$ and $\alpha$

Searching for a preferable pair of $\lambda$ and $\alpha$ is subjective.
Some defaults are provided but the user is encouraged to explore and consider
other possible solutions.


## Univariate Response

Searching for a combination of $\lambda$ and $\alpha$ resulting in the lowest
cross validation error is done with a call to `ensr`.  The arguments to
`ensr` are the same as those made to `cv.glment` with the addition of
`alphas`, a sequence of $\alpha$ values to use.  Please note that `ensr` will
add `length(alphas) - 1` additional values, the midpoint between the given
set, in the construciton of a $\lambda$--$\alpha$ grid to search.  For the
initial example we will fit an elastic net for modeling the evaporation in
the landfill data constructed above.

```{r }
set.seed(42)
y_matrix <- as.matrix(landfill$evap)
x_matrix <- as.matrix(landfill[, topsoil_porosity:weather_temp])

ensr_obj <- ensr(y = y_matrix, x = x_matrix, standardize = FALSE)
ensr_obj
```


The `ensr_obj` is a `ensr` object which is a list of `cv.glment` objects.
The length of the list is determined by the length of the $\alphas$ argument.
The default for `alphas` is `r deparse(as.list(args(ensr))$alphas)`.

The summary method for `ensr` objects returns and `data.table` with value of
$\lambda$, $\alpha$, the mean cross-validation error `cvm`, and the number of
non-zero coefficients.  The `l_index` the the list index of the `ensr` object
associated with the noted $\alpha$ value.

```{r }
ensr_obj_summary <- summary(object = ensr_obj)
ensr_obj_summary
```


The preferable model is the one with the minimum cross-validation error.

```{r }
ensr_obj_summary[cvm == min(cvm)]
```


A quick way to get the preferable model is to call the `preferable` method.

```{r }
str( preferable(ensr_obj), max.level = 1L)
```


The return is a `elnet` `glmnet` object with one additional list element, the
`ensr_summary` used to select this preferable model.

Since the return of `preferable` inherits the same class as a object
returned from a call to `glmnet::glmnet` the same methods can be used, for
example, plotting

```{r }
par(mfrow = c(1, 3))
plot(preferable(ensr_obj), xvar = "norm")
plot(preferable(ensr_obj), xvar = "lambda")
plot(preferable(ensr_obj), xvar = "dev")
```


Another graphical way to look at the results of the `ensr` is to use the
provided plotting method.  In the plot below each of the $\lambda$ (y-axis,
$\log_{10}$ scale) and $\alpha$ (x-axis) values considered in the `ensr_obj`
are plotted.  The coloring is denoted as `log10(z)` where `z = (cvm -
min(cvm)) / sd(cvm)`.   The color scale is set to have low values, values
near the minimum mean cross validation error, to be dark green, values moving
further from the min are lighter green, moving to white then purple.

```{r }
plot(ensr_obj) +
  theme_bw() +
  facet_zoom(x = 0.50 < alpha & alpha < 0.90, y = 5e-4 < lambda & lambda < 1.5e-3)
```


In this graphic we see the minimum mean cross validation error occurs within
the models with $\alpha$ = `r summary(ensr_obj)[cvm == min(cvm), "alpha"]`.

```{r }
summary(ensr_obj)[cvm == min(cvm)]
```


Inspection of the plot suggest there is another minimum worth looking at, for
$\alpha$ = `r summary(ensr_obj)[l_index == 16][cvm == min(cvm), "alpha"]`.

```{r }
summary(ensr_obj)[, .SD[cvm == min(cvm)], by = alpha][l_index %in% c(13, 16)]
```


The difference in the mean cross validation error between these two results
is very small, and perhaps is not meaningful.  What is notable is that the
number of non-zero (`nzero`) coefficients are different.  With a very small
increase in the mean cross validation error, one more variable has its
regression coefficient shrunk to zero.  If parsimony is your primary
objective the second model might be your preferable model.

We can look at the mean cross validation errors by nzero too.

```{r }
summary(ensr_obj)[, .SD[cvm == min(cvm)], by = nzero]

ggplot(summary(ensr_obj)[, .SD[cvm == min(cvm)], by = nzero]) +
  theme_bw() +
  aes(x = nzero, y = cvm) +
  geom_point() +
  geom_line() +
  facet_zoom(xy = cvm < 0.05)
```


Based on the graphic above, if the objective is lowest cross validation error
and parsimony, you could argue that the model with 14 non-zero coefficients
is the preferable model as the is very little to gain, in terms of reducing
the mean cross validation error, by using a model with fifteen or more
non-zero coefficients.  But then again, that argument could be made about the
model with only five non-zero coefficients.

```{r }
summary(ensr_obj)[nzero %in% c(5, 15)] [, .SD[cvm == min(cvm)], by = nzero]
```


To get the set of coefficients associated with the above:

```{r }
landfill_evap_coef5  <- coef(ensr_obj[[19]], s = 0.0020028865)
landfill_evap_coef15 <- coef(ensr_obj[[16]], s = 0.0007266755)
```


The table below lists the variables for each model in descending order of the
absolute value of the regression coefficients.  Since the predictors had been
standardized the relative magnitude of the coefficients can server has a
sensitivity/influence/importance metric.

```{r }
qwraps2::qable(
               data.table(
                          variable = c(rownames(landfill_evap_coef5),
                                       rownames(landfill_evap_coef15)),
                          value    = c(as.vector(matrix(landfill_evap_coef5)),
                                       as.vector(matrix(landfill_evap_coef15))),
                          nzero    = c(rep(5, 36), rep(15, 36))
                          )[
                            abs(value) >= 1e-10 & variable != "(Intercept)"
                            ][
                            order(nzero, -abs(value))
                            ][
                            ,
                            nzero := NULL
                            ]
               ,
               rgroup = c("nzero = 5" = 5, "nzero = 15"= 15),
               rnames = c(1:5, 1:15))
```


The variables most important for modeling evaporation are `weather_temp`
(average temperature over the last 100 years),
`wind` (average wind speed), `weather_solrad` (average solar radiation), and
`rh` (relative humidity).  The magnitude of the fifth and lower ranked
variables is considerably smaller than these four and thus not as important.


## Cross Validation Issues

The results above are subject to the foldid, as shown below:

```{r }
foldid1 <- sample(seq(10), size = nrow(x_matrix), replace = TRUE)
foldid2 <- sample(seq(10), size = nrow(x_matrix), replace = TRUE)
foldid3 <- sample(seq(10), size = nrow(x_matrix), replace = TRUE)

ensr_obj_1 <- ensr(y = y_matrix, x = x_matrix, standardize = FALSE, foldid = foldid1)
ensr_obj_2 <- ensr(y = y_matrix, x = x_matrix, standardize = FALSE, foldid = foldid2)
ensr_obj_3 <- ensr(y = y_matrix, x = x_matrix, standardize = FALSE, foldid = foldid3)

summary(ensr_obj_1)[cvm == min(cvm)]
summary(ensr_obj_2)[cvm == min(cvm)]
summary(ensr_obj_3)[cvm == min(cvm)]
```


There are small differences in the cross validation errors and the in the
$\lambda$ values.  There is a large difference, in the $\alpha$ values.  It
is notable, that the differences in the regression coefficients is minor.
In this case there are the same number of non-zero coefficients and the
magnitudes are similar.

```{r }
cbind(coef(ensr_obj_1), coef(ensr_obj_2), coef(ensr_obj_3))
```


One could argue there is a major difference in the result between the two
foldid.  Using the cvm, the `foldid3` leads to 18 non-zero coefficients
whereas foldid1 and foldid2 leads to only 14 non-zero coefficients.

It is recommended multiple CV runs or bootstrapping is used to select a
preferable model.


## Multivariate Response


There are three outcomes, injuries, in the `tbi` data set.  It would be
reasonable to assume that there should be common variables with non-zero
coefficients for models of each injury.  The end user could fit three
univariate models, or, fit one multinomial model via the tools provided by
`glmnet`.

To illustrate these options we will run `ensr` five times: three univariate
models, one multinomial model with `type.multinomial`

```{r }
ymat_1 <- matrix(tbi$injury1, ncol = 1)
ymat_2 <- matrix(tbi$injury2, ncol = 1)
ymat_3 <- matrix(tbi$injury3, ncol = 1)
ymat_123 <- as.matrix(tbi[, c("injury1", "injury2", "injury3")], ncol = 3)
xmat     <- as.matrix(tbi[, -c("injury1", "injury2", "injury3")])
xmat[, "age"] <- standardize(xmat[, "age"])
xmat[, "los"] <- standardize(xmat[, "los"])

foldid <- sample(seq(10), size = nrow(ymat_1), replace = TRUE)

fit_1 <- ensr(y = ymat_1, x = xmat,
              standardize = FALSE, standardize.response = FALSE,
              foldid = foldid, family = "binomial")
fit_2 <- ensr(y = ymat_2, x = xmat,
              standardize = FALSE, standardize.response = FALSE,
              foldid = foldid, family = "binomial")
fit_3 <- ensr(y = ymat_3, x = xmat,
              standardize = FALSE, standardize.response = FALSE,
              foldid = foldid, family = "binomial")
fit_123_ungrouped <-
  ensr(y = ymat_123, x = xmat,
       standardize = FALSE, standardize.response = FALSE,
       foldid = foldid,
       family = "multinomial",
       type.multinomial = "ungrouped")
fit_123_grouped <-
  ensr(y = ymat_123, x = xmat,
       standardize = FALSE, standardize.response = FALSE,
       foldid = foldid,
       family = "multinomial",
       type.multinomial = "grouped")
```


Let's look at the plots for these fits.  Looking for models that simply
minimize cross-validation error suggests that for injury2 and injury3 an
$\alpha$ of 1 would be preferable.   For injury1, a slightly lower $\alpha$
is preferable.   When fitting the multinomial responses, grouped or
ungrouped, it appears that preferable $\alpha$ is similar to the univariate
fits.


```{r fig.width = 8, fig.height = 8}
gridExtra::grid.arrange(
plot(fit_1) + ggplot2::ggtitle("Fit 1"),
plot(fit_2) + ggplot2::ggtitle("Fit 2"),
plot(fit_3) + ggplot2::ggtitle("Fit 3"),
plot(fit_123_ungrouped) + ggplot2::ggtitle("Fit 123 Ungrouped"),
plot(fit_123_grouped) + ggplot2::ggtitle("Fit 123 Grouped"),
layout_matrix = rbind(c(1, 1, 2, 2, 3, 3),
                      c(4, 4, 4, 5, 5, 5)))
```


The summary for these models

```{r }
all_summaries <-
  rbindlist(list(summary(fit_1),
                 summary(fit_2),
                 summary(fit_3),
                 summary(fit_123_ungrouped),
                 summary(fit_123_grouped)),
            idcol = "fit")
```


And the preferable models are:

```{r }
all_summaries[, .SD[cvm == min(cvm)], by = fit]
```




```{r }
ggplot(
       all_summaries[, .SD[cvm == min(cvm)], by = c("fit", "nzero")]
       ) +
  theme_bw() +
  aes(x = nzero, y = cvm, color = factor(fit), linetype = factor(fit)) +
  geom_point() +
  geom_line() 

all_summaries[, .SD[cvm == min(cvm) & ((fit == 4 & nzero == 9) | (fit == 5 & nzero == 14))], by = c("fit", "nzero")]
```


Lastly, similar work and can be done for multivariate Gaussian responses.
See the documentation for `glmnet` for details.


# Session Info


```{r }
print(sessionInfo(), local = FALSE)
```


# References

